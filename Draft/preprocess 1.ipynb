{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The file Medical_dataset/intents_short.json does not exist.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "file_path = 'Medical_dataset/intents_short.json'\n",
    "\n",
    "# Check if the file exists\n",
    "if not os.path.exists(file_path):\n",
    "    print(f\"The file {file_path} does not exist.\")\n",
    "else:\n",
    "    with open(file_path, 'r') as file:\n",
    "        data = json.load(file)\n",
    "        print(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/etd/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /home/etd/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /home/etd/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "import numpy as np\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy.lang.en.stop_words import STOP_WORDS\n",
    "import spacy\n",
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(doc):\n",
    "    doc=doc.replace(\"'t\",' not')\n",
    "    nlp_doc=nlp(doc)\n",
    "    d=[]\n",
    "    for token in nlp_doc:\n",
    "        if(not token.text.lower()  in STOP_WORDS and  token.text.isalpha()):\n",
    "            d.append(token.lemma_.lower() )\n",
    "    return ' '.join(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stp=stopwords.words('english')\n",
    "stp.remove('not')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_sent(sent):\n",
    "    sent=sent.replace(\"'t\",' not')\n",
    "    t=nltk.word_tokenize(sent)\n",
    "    return ' '.join([lemmatizer.lemmatize(w.lower()) for w in t if (w not in stp and w.isalpha())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'not breath'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocess_sent(\"i can't breath\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent=[]\n",
    "app_tag=[]\n",
    "for intent in intents['intents']:\n",
    "    tag = intent['tag']\n",
    "    for pattern in intent['patterns']:\n",
    "        sent.append(preprocess_sent(pattern))\n",
    "        app_tag.append(tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer()\n",
    "vectors = vectorizer.fit_transform(sent)\n",
    "feature_names = vectorizer.get_feature_names()\n",
    "dense = vectors.todense()\n",
    "denselist = dense.tolist()\n",
    "df = pd.DataFrame(denselist, columns=feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab=list(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bag_of_words(tokenized_sentence, all_words):\n",
    "    bag = np.zeros(len(all_words), dtype=np.float32)\n",
    "    for idx, w in enumerate(all_words):\n",
    "        if w in tokenized_sentence:\n",
    "            bag[idx] = 1.0\n",
    "    return bag"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# synthetic dataset created for neural network validation\n",
    "xy_test = [\n",
    "    (['can',\"'t\", 'think', 'straight'], 'altered_sensorium'),\n",
    "    (['suffer', 'from', 'anxeity'], 'anxiety'),\n",
    "    (['suffer', 'from', 'anxeity'], 'anxiety'),\n",
    "    (['bloody', 'poop'], 'bloody_stool'),\n",
    "    (['blurred', 'vision'], 'blurred_and_distorted_vision'),\n",
    "    (['can', \"'t\", 'breathe'], 'breathlessness'),\n",
    "    (['Yellow', 'liquid', 'pimple'], 'yellow_crust_ooze'),\n",
    "    (['lost', 'weight'], 'weight_loss'),\n",
    "    (['side', 'weaker'], 'weakness_of_one_body_side'),\n",
    "    (['watering', 'eyes'], 'watering_from_eyes'),\n",
    "    (['brief', 'blindness'], 'visual_disturbances'),\n",
    "    (['throat', 'hurts'], 'throat_irritation'),\n",
    "    (['extremities', 'swelling'], 'swollen_extremeties'),\n",
    "    (['swollen', 'lymph', 'nodes'], 'swelled_lymph_nodes'),\n",
    "    (['dark', 'under', 'eyes'], 'sunken_eyes'),\n",
    "    (['stomach', 'blood'], 'stomach_bleeding'),\n",
    "    (['blood', 'urine'], 'spotting_urination'),\n",
    "    (['sinuses', 'hurt'], 'sinus_pressure'),\n",
    "    (['watery', 'from', 'nose'], 'runny_nose'),\n",
    "    (['have', 'to', 'move'], 'restlessness'),\n",
    "    (['red', 'patches', 'body'], 'red_spots_over_body'),\n",
    "    (['sneeze'], 'continuous_sneezing'),\n",
    "    (['coughing'], 'cough'),\n",
    "    (['skin', 'patches'], 'dischromic_patches'),\n",
    "    (['skin', 'bruised'], 'bruising'),\n",
    "    (['burning', 'pee'], 'burning_micturition'),\n",
    "    (['hurts', 'pee'], 'burning_micturition'),\n",
    "    (['Burning', 'sensation'], 'burning_micturition'),\n",
    "    (['chest', 'pressure'], 'chest_pain'),\n",
    "    (['pain', 'butt'], 'pain_in_anal_region'),\n",
    "    (['heart', 'bad', 'beat'], 'palpitations'),\n",
    "    (['fart', 'lot'], 'passage_of_gases'),\n",
    "    (['cough', 'phlegm'], 'phlegm'),\n",
    "    (['lot', 'urine'], 'polyuria'),\n",
    "    (['Veins', 'bigger'], 'prominent_veins_on_calf'),\n",
    "    (['Veins', 'emphasized'], 'prominent_veins_on_calf'),\n",
    "    (['yellow', 'pimples'], 'pus_filled_pimples'),\n",
    "    (['red', 'nose'], 'red_sore_around_nose'),\n",
    "    (['skin', 'yellow'], 'yellowish_skin'),\n",
    "    (['eyes', 'yellow'], 'yellowing_of_eyes'),\n",
    "    (['large', 'thyroid'], 'enlarged_thyroid'),\n",
    "    (['really', 'hunger'], 'excessive_hunger'),\n",
    "    (['always', 'hungry'], 'excessive_hunger'),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.to_csv(r'tfidfsymptoms.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_test(sent):\n",
    "    return [lemmatizer.lemmatize(w.lower()) for w in sent if (w not in set(stopwords.words('english')) and w.isalpha())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'not think straight'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocess_sent(' '.join(xy_test[0][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "not think straight\n",
      "suffer anxeity\n",
      "suffer anxeity\n",
      "bloody poop\n",
      "blurred vision\n",
      "not breathe\n",
      "yellow liquid pimple\n",
      "lost weight\n",
      "side weaker\n",
      "watering eye\n",
      "brief blindness\n",
      "throat hurt\n",
      "extremity swelling\n",
      "swollen lymph node\n",
      "dark eye\n",
      "stomach blood\n",
      "blood urine\n",
      "sinus hurt\n",
      "watery nose\n",
      "move\n",
      "red patch body\n",
      "sneeze\n",
      "coughing\n",
      "skin patch\n",
      "skin bruised\n",
      "burning pee\n",
      "hurt pee\n",
      "burning sensation\n",
      "chest pressure\n",
      "pain butt\n",
      "heart bad beat\n",
      "fart lot\n",
      "cough phlegm\n",
      "lot urine\n",
      "vein bigger\n",
      "vein emphasized\n",
      "yellow pimple\n",
      "red nose\n",
      "skin yellow\n",
      "eye yellow\n",
      "large thyroid\n",
      "really hunger\n",
      "always hungry\n"
     ]
    }
   ],
   "source": [
    "y_true=[]\n",
    "y_pred=[]\n",
    "for x,y in xy_test:\n",
    "    y_true.append(y)\n",
    "    p=preprocess_sent(' '.join(x))\n",
    "    print(p)\n",
    "    bow=np.array(bag_of_words(p,vocab))\n",
    "    #    bow=vectorizer.transform(p).toarray()\n",
    "    res=cosine_similarity(bow.reshape((1, -1)), df).reshape(-1)\n",
    "    y_pred.append(app_tag[np.argmax(res)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['altered_sensorium',\n",
       " 'anxiety',\n",
       " 'anxiety',\n",
       " 'constipation',\n",
       " 'blurred_and_distorted_vision',\n",
       " 'loss_of_appetite',\n",
       " 'yellow_crust_ooze',\n",
       " 'weight_loss',\n",
       " 'weakness_of_one_body_side',\n",
       " 'watering_from_eyes',\n",
       " 'visual_disturbances',\n",
       " 'patches_in_throat',\n",
       " 'restlessness',\n",
       " 'swelled_lymph_nodes',\n",
       " 'sunken_eyes',\n",
       " 'belly_pain',\n",
       " 'spotting_urination',\n",
       " 'sinus_pressure',\n",
       " 'runny_nose',\n",
       " 'restlessness',\n",
       " 'red_spots_over_body',\n",
       " 'continuous_sneezing',\n",
       " 'cough',\n",
       " 'patches_in_throat',\n",
       " 'bruising',\n",
       " 'burning_micturition',\n",
       " 'burning_micturition',\n",
       " 'burning_micturition',\n",
       " 'chest_pain',\n",
       " 'pain_in_anal_region',\n",
       " 'palpitations',\n",
       " 'passage_of_gases',\n",
       " 'phlegm',\n",
       " 'polyuria',\n",
       " 'prominent_veins_on_calf',\n",
       " 'prominent_veins_on_calf',\n",
       " 'pus_filled_pimples',\n",
       " 'red_sore_around_nose',\n",
       " 'yellowish_skin',\n",
       " 'yellowing_of_eyes',\n",
       " 'enlarged_thyroid',\n",
       " 'excessive_hunger',\n",
       " 'excessive_hunger']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "error=0\n",
    "for i in range(len(y_pred)):\n",
    "    if y_pred[i]!=y_true[i]:\n",
    "        error+=1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8604651162790697"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1-error/len(y_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'breathlessness'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x=['breathe']\n",
    "p=preprocess_sent(' '.join(x))\n",
    "bow=np.array(bag_of_words(p,vocab))\n",
    "res=cosine_similarity(bow.reshape((1, -1)), df).reshape(-1)\n",
    "app_tag[np.argmax(res)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=np.argsort(res)[::-1][:2].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DEPLOIMENT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('tfidfsymptoms.csv')\n",
    "vocab=list(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "knn= joblib.load('knn.pkl')  \n",
    "#knn_from_joblib.predict(X_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bag_of_words(tokenized_sentence, all_words):\n",
    "    bag = np.zeros(len(all_words), dtype=np.float32)\n",
    "    for idx, w in enumerate(all_words):\n",
    "        if w in tokenized_sentence:\n",
    "            bag[idx] = 1.0\n",
    "    return bag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predictSym(sym,vocab,app_tag):\n",
    "    sym=preprocess_sent(sym)\n",
    "    bow=np.array(bag_of_words(sym,vocab))\n",
    "    res=cosine_similarity(bow.reshape((1, -1)), df).reshape(-1)\n",
    "    order=np.argsort(res)[::-1].tolist()\n",
    "    possym=[]\n",
    "    for i in order:\n",
    "        if app_tag[i].replace('_',' ') in sym:\n",
    "            return app_tag[i],1\n",
    "        if app_tag[i] not in possym and res[i]!=0:\n",
    "            possym.append(app_tag[i])\n",
    "    return possym,0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['nodal_skin_eruptions',\n",
       "  'skin_rash',\n",
       "  'yellowish_skin',\n",
       "  'silver_like_dusting',\n",
       "  'dischromic_patches',\n",
       "  'skin_peeling',\n",
       "  'sunken_eyes'],\n",
       " 0)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictSym('i have skin erumptions',vocab,app_tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tr=pd.read_csv('Medical_dataset/Training.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "disease=df_tr.iloc[:,-1].to_list()\n",
    "all_symp_col=list(df_tr.columns[:-1])\n",
    "all_symp=[clean_symp(sym) for sym in (all_symp_col)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#recoit client_symptoms et renvoit un dataframe avec 1 pour les symptoms associees\n",
    "def OHV(cl_sym,all_sym):\n",
    "    l=np.zeros([1,len(all_sym)])\n",
    "    for sym in cl_sym:\n",
    "        l[0,all_sym.index(sym)]=1\n",
    "    return pd.DataFrame(l, columns =all_symp)\n",
    "\n",
    "def contains(small, big):\n",
    "    a=True\n",
    "    for i in small:\n",
    "        if i not in big:\n",
    "            a=False\n",
    "    return a\n",
    "\n",
    "def possible_diseases(l,disease):\n",
    "    poss_dis=[]\n",
    "    for dis in set(disease):\n",
    "        if contains(l,symVONdisease(df_tr,dis)):\n",
    "            poss_dis.append(dis)\n",
    "    return poss_dis\n",
    "\n",
    "def possible_diseases(l):\n",
    "    poss_dis=[]\n",
    "    for dis in set(disease):\n",
    "        if contains(l,symVONdisease(df_tr,dis)):\n",
    "            poss_dis.append(dis)\n",
    "    return poss_dis\n",
    "\n",
    "#recoit une maladie renvoit tous les sympts\n",
    "def symVONdisease(df,disease):\n",
    "    ddf=df[df.prognosis==disease]\n",
    "    m2 = (ddf == 1).any()\n",
    "    return m2.index[m2].tolist()\n",
    "    \n",
    "def clean_symp(sym):\n",
    "    return sym.replace('_',' ').replace('.1','').replace('(typhos)','').replace('yellowish','yellow').replace('yellowing','yellow') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['continuous_sneezing', 'shivering', 'chills', 'watering_from_eyes']"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "symVONdisease(df_tr,'Allergy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getInfo():\n",
    "    # name=input(\"Name:\")\n",
    "    print(\"Your Name \\n\\t\\t\\t\\t\\t\\t\",end=\"=>\")\n",
    "    name=input(\"\")\n",
    "    print(\"hello \",name)\n",
    "    return str(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "severityDictionary=dict()\n",
    "description_list = dict()\n",
    "precautionDictionary=dict()\n",
    "\n",
    "def getDescription():\n",
    "    global description_list\n",
    "    with open('symptom_Description.csv') as csv_file:\n",
    "        csv_reader = csv.reader(csv_file, delimiter=',')\n",
    "        line_count = 0\n",
    "        for row in csv_reader:\n",
    "            _description={row[0]:row[1]}\n",
    "            description_list.update(_description)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def getSeverityDict():\n",
    "    global severityDictionary\n",
    "    with open('symptom_severity.csv') as csv_file:\n",
    "\n",
    "        csv_reader = csv.reader(csv_file, delimiter=',')\n",
    "        line_count = 0\n",
    "        try:\n",
    "            for row in csv_reader:\n",
    "                _diction={row[0]:int(row[1])}\n",
    "                severityDictionary.update(_diction)\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "\n",
    "def getprecautionDict():\n",
    "    global precautionDictionary\n",
    "    with open('symptom_precaution.csv') as csv_file:\n",
    "\n",
    "        csv_reader = csv.reader(csv_file, delimiter=',')\n",
    "        line_count = 0\n",
    "        for row in csv_reader:\n",
    "            _prec={row[0]:[row[1],row[2],row[3],row[4]]}\n",
    "            precautionDictionary.update(_prec)\n",
    "\n",
    "def calc_condition(exp,days):\n",
    "    sum=0\n",
    "    for item in exp:\n",
    "         sum=sum+severityDictionary[item]\n",
    "    if((sum*days)/(len(exp))>13):\n",
    "        return 1\n",
    "        print(\"You should take the consultation from doctor. \")\n",
    "    else:\n",
    "        return 0\n",
    "        print(\"It might not be that bad but you should take precautions.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "getSeverityDict()\n",
    "getprecautionDict()\n",
    "getDescription()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main_sp(name):\n",
    "    #main Idea: At least two initial sympts to start with\n",
    "    \n",
    "    #get the 1st syp ->> process it ->> check_pattern ->>> get the appropriate one (if check_pattern==1 == similar syntaxic symp found)\n",
    "    print(\"Hi Mr/Ms \"+name+\", can you describe you main symptom ?  \\n\\t\\t\\t\\t\\t\\t\",end=\"=>\")\n",
    "    sym1 = input(\"\")\n",
    "    psym1,find=predictSym(sym1,vocab,app_tag)\n",
    "    if find==1:\n",
    "        sym1=psym1\n",
    "    else:\n",
    "        i=0\n",
    "        while True and i<len(psym1):\n",
    "            print('Do you experience '+psym1[i].replace('_',' '))\n",
    "            rep=input(\"\")\n",
    "            if str(rep)=='yes':\n",
    "                sym1=psym1[i]\n",
    "                break\n",
    "            else:\n",
    "                i=i+1\n",
    "\n",
    "    print(\"Is there any other symtom Mr/Ms \"+name+\"  \\n\\t\\t\\t\\t\\t\\t\",end=\"=>\")\n",
    "    sym2=input(\"\")\n",
    "    psym2,find=predictSym(sym2,vocab,app_tag)\n",
    "    if find==1:\n",
    "        sym2=psym2\n",
    "    else:\n",
    "        i=0\n",
    "        while True and i<len(psym2):\n",
    "            print('Do you experience '+psym2[i].replace('_',' '))\n",
    "            rep=input(\"\")\n",
    "            if str(rep)=='yes':\n",
    "                sym2=psym2[i]\n",
    "                break\n",
    "            else:\n",
    "                i=i+1\n",
    "    \n",
    "    #create patient symp list\n",
    "    all_sym=[sym1,sym2]\n",
    "    #predict possible diseases\n",
    "    diseases=possible_diseases(all_sym)\n",
    "    stop=False\n",
    "    print(\"Are you experiencing any \")\n",
    "    for dis in diseases:\n",
    "        if stop==False:\n",
    "            for sym in symVONdisease(df_tr,dis):\n",
    "                if sym not in all_sym:\n",
    "                    print(clean_symp(sym)+' ?')\n",
    "                    while True:\n",
    "                        inp=input(\"\")\n",
    "                        if(inp==\"yes\" or inp==\"no\"):\n",
    "                            break\n",
    "                        else:\n",
    "                            print(\"provide proper answers i.e. (yes/no) : \",end=\"\")\n",
    "                    if inp==\"yes\":\n",
    "                        all_sym.append(sym)\n",
    "                        dise=possible_diseases(all_sym)\n",
    "                        if len(dise)==1:\n",
    "                            stop=True \n",
    "                            break\n",
    "                    else:\n",
    "                        continue\n",
    "    return knn.predict(OHV(all_sym,all_symp_col)),all_sym"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat_sp():\n",
    "    a=True\n",
    "    while a:\n",
    "        name=getInfo()\n",
    "        result,sym=main_sp(name)\n",
    "        if result == None :\n",
    "            ans3=input(\"can you specify more what you feel or tap q to stop the conversation\")\n",
    "            if ans3==\"q\":\n",
    "                a=False\n",
    "            else:\n",
    "                continue\n",
    "\n",
    "        else:\n",
    "            print(\"you may have \"+result[0])\n",
    "            print(description_list[result[0]])\n",
    "            an=input(\"how many day do you feel those symptoms ?\")\n",
    "            if calc_condition(sym,int(an))==1:\n",
    "                print(\"you should take the consultation from doctor\")\n",
    "            else : \n",
    "                print('Take following precautions : ')\n",
    "                for e in precautionDictionary[result[0]]:\n",
    "                    print(e)\n",
    "            print(\"do you need another medical consultation (yes or no)? \")\n",
    "            ans=input()\n",
    "            if ans!=\"yes\":\n",
    "                a=False\n",
    "                print(\"!!!!! thanks for using ower application !!!!!! \")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_sp()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
